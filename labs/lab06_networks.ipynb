{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamilton-at-CapU/comp215/blob/main/labs/lab06_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbDMwwMgFNX1"
      },
      "source": [
        "COMP 215 - LAB 6\n",
        "----------------\n",
        "#### Name(s):\n",
        "#### Date:\n",
        "\n",
        "By the end of this lab you should be able to:\n",
        "  * create a Watts-Strogatz graph both from scratch and from the Networkx module\n",
        "  * measure the average clustering coefficient and path length of a network\n",
        "  * visualize summative data of a graph\n",
        "\n",
        "\n",
        "During this lab, you will be introduced to the following:\n",
        "  * numpy arrays\n",
        "  * local file i/o in Google Colab\n",
        "\n",
        "(this lab is based on workbooks provided in Allen Downey's 'Think Complexity')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJiS-F9RzzdV"
      },
      "source": [
        "## Social Networking\n",
        "\n",
        "This lab uses graphs to explore social networks using Facebook data.  In this lab you will create a simulated model of the network using a Watts-Strogatz graph and compare some properties of the simulated network and the real Facebook network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXutG9U4uFwC"
      },
      "outputs": [],
      "source": [
        "# put your imports here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-WCMvBZiuIOV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "import scipy as sp\n",
        "import random\n",
        "from collections import deque"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erejuo3kzzdV"
      },
      "source": [
        "## Get the Facebook Data\n",
        "\n",
        "Stanford Network Analysis Platform (SNAP) is a general purpose network analysis and graph mining library.  In previous labs, we have used APIs to access data.  For this lab, we will copy the data to a local file.  Download the ```facebook_combined.txt.gz``` file from [SNAP](https://snap.stanford.edu/data/egonets-Facebook.html), unzip it, and copy ```facebook_combined.txt``` to the ```Files``` folder in Colab.  \n",
        "\n",
        "Look at the content of the file and read the SNAP webpage to understand what the data represents before moving on to the rest of the lab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efqf1iZusG9l"
      },
      "source": [
        "## Exercise 1: Make Facebook Graph\n",
        "\n",
        "Write a function that reads the file, one edge per line, specified by the two integer node IDs given in each line of the file and returns a ```networkx``` graph representing the data.  You can do this with Python's built-in file handling, or you could use ```numpy```'s ```loadtxt``` function.  Write a unit test to check that the network has 4039 nodes and 88234 edges (as given in the Dataset Statistics on the SNAP site) and draw the Facebook network (this takes about a minute).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bWXTcAS5tiA_"
      },
      "outputs": [],
      "source": [
        "# Ex 1 code here\n",
        "\n",
        "def create_fb_graph():\n",
        "    value = np.loadtxt('facebook_combined.txt')\n",
        "    # print(\"val\", value)\n",
        "    \n",
        "    G = nx.Graph()\n",
        "    # I think there is an nx function to do this\n",
        "    for i in range(len(value)):\n",
        "        G.add_edge(value[i][0], value[i][1])\n",
        "    \n",
        "    # nx.draw(G)\n",
        "    return G\n",
        "    \n",
        "create_fb_graph()\n",
        "\n",
        "def test_fb_graph():\n",
        "    G = create_fb_graph()\n",
        "    \n",
        "    assert G.number_of_nodes() == 4039, \"Incorrect number of nodes\"\n",
        "    assert G.number_of_edges() == 88234, \"Incorrect number of edges\"\n",
        "    \n",
        "test_fb_graph()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXPh29uSzzde"
      },
      "source": [
        "## Exercise 2: Clustering Coefficients\n",
        "\n",
        "With larger graphs, it can take a long time to compute clustering coefficients and path lengths. We can estimate them by sampling without much loss of accuracy if the sample size is large enough.  Write a function that calculates the average clustering coeffient for a random subset of a N pairs of nodes in a network.  You may use the ```node_clustering``` and ```all_pairs``` functions from Chapter 5 of the textbook.  You may also use the ```numpy``` module to calculate the mean; note that there is a ```nanmean``` function.\n",
        "\n",
        "Check that your clustering coeffients function gives a similar answer to the ```networkx``` ```average_clustering``` function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4ECxHRHA38GQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proper avg clustering 0.6055467186200862\n",
            "My avg clustering 0.5961823277359227\n",
            "Sample clustering error 0.012584371100077374\n"
          ]
        }
      ],
      "source": [
        "# Ex 2 code here\n",
        "\n",
        "def find_avg_clustering(n: int):\n",
        "    G = create_fb_graph()\n",
        "    \n",
        "    sample = random.sample(list(G.nodes), n)\n",
        "    \n",
        "    cluster_sample: dict[int, float] = nx.clustering(G, sample) # type: ignore\n",
        "    \n",
        "    mean = np.mean(np.array(list(cluster_sample.values())))\n",
        "    return mean\n",
        "    \n",
        "def test_find_avg_clustering():\n",
        "    n = 100\n",
        "    \n",
        "    test_graph = create_fb_graph()\n",
        "    \n",
        "    true_clustering = nx.average_clustering(test_graph)\n",
        "    sample_clustering = find_avg_clustering(n)\n",
        "    \n",
        "    print(\"Proper avg clustering\", nx.average_clustering(test_graph))\n",
        "    print(\"My avg clustering\", find_avg_clustering(n))\n",
        "    \n",
        "    print(\"Sample clustering error\", abs(true_clustering - sample_clustering))\n",
        "    \n",
        "test_find_avg_clustering()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTTwpgCqzzdi"
      },
      "source": [
        "## Exercise 3: Average Shortest Path Length\n",
        "\n",
        "Write a function that calculates the average shortest path length for all pairs of nodes in a network.  You may use the ```shortest_path_dijkstra``` function from Chapter 5 of the textbook.  Using that function, it took my algorithm about 2 minutes to find the average shortest path over all pairs of nodes.\n",
        "\n",
        "\n",
        "Check that your average shortest path length function gives a similar answer to the ```networkx``` ```average_shortest_path_length``` function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjUys_tj6xV2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<generator object all_pairs_dijkstra at 0x7fa0501a8f20>\n",
            "Proper shortest path 3.6925068496963913\n",
            "<generator object all_pairs_dijkstra at 0x7fa0501a8ae0>\n",
            "My shortest path 3.6925068496963913\n",
            "Shortest path error 0.0\n"
          ]
        }
      ],
      "source": [
        "# Ex 3 code here\n",
        "\n",
        "def find_shortest_path():\n",
        "    G = create_fb_graph()\n",
        "    \n",
        "    # length_map = nx.shortest_path(G)\n",
        "    \n",
        "    # lengths = [length_map[u][v] for u, v in ]\n",
        "    \n",
        "    paths = dict(nx.all_pairs_dijkstra(G))\n",
        "    \n",
        "    # mean_shortest_path = np.mean(list(length_map))\n",
        "    \n",
        "    print(paths)\n",
        "    \n",
        "    return nx.average_shortest_path_length(G)\n",
        "    \n",
        "def test_find_shortest_path():\n",
        "    test_graph = create_fb_graph()\n",
        "    \n",
        "    true_shortest_path = nx.average_shortest_path_length(test_graph)\n",
        "    test_shortest_path = find_shortest_path()\n",
        "    \n",
        "    print(\"Proper shortest path\", nx.average_shortest_path_length(test_graph))\n",
        "    print(\"My shortest path\", find_shortest_path())\n",
        "    \n",
        "    print(\"Shortest path error\", abs(true_shortest_path - test_shortest_path))\n",
        "    \n",
        "test_find_shortest_path()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBkY9Y2RRPA8"
      },
      "source": [
        "Here is a function from the textbook that takes a sample of path lengths to estimate the average shortest path length.  You may use this in the rest of the lab so that you don't need to wait for the whole full averaging algorithms above to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhco0N1Wzzdj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sample_path_lengths(G, nodes=None, trials=100):\n",
        "    \"\"\"Choose random pairs of nodes and compute the path length between them.\n",
        "    G: Graph\n",
        "    N: number of pairs to choose\n",
        "    returns: list of path lengths\n",
        "    \"\"\"\n",
        "    if nodes is None:\n",
        "        nodes = list(G)\n",
        "    else:\n",
        "        nodes = list(nodes)\n",
        "\n",
        "    pairs = np.random.choice(nodes, (trials, 2))\n",
        "    lengths = [nx.shortest_path_length(G, *pair)\n",
        "               for pair in pairs]\n",
        "    return lengths\n",
        "\n",
        "def estimate_path_length(G, nodes=None, trials=1000):\n",
        "    return np.mean(sample_path_lengths(G, nodes, trials))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwX8KqjbRumD"
      },
      "source": [
        "In the exercises above, you should have found that the Facebook network has an average clustering coefficient around 0.6 and an average shortest path length of around 3.7. Note that this corresponds to a 'degree of separation' of less than 6.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4eI_fYczzds"
      },
      "source": [
        "## Exercise 4: WS Graph\n",
        "\n",
        "Construct a WS graph with the same number of nodes and average degree as the Facebook network using the ```make_ws_graph``` function from Chapter 5.  Find the value of p (probability of rewire) that reproduces a clustering coefficient and average shortest path length of the Facebook network.  (Note that there is a ```nx.watts_strogatz_graph``` that you may use after you have demonstrated that you can create a WS graph using the functions from Chapter 5.).\n",
        "\n",
        "What could this value of p tell you about the actual social network that this Facebook data represents?  (Think about what p means in the model and what that would represent in the data.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lQ149MrVHhX"
      },
      "outputs": [],
      "source": [
        "# Ex 4 code here\n",
        "\n",
        "def find_simulated_fb_p():\n",
        "    pass\n",
        "\n",
        "def make_watts_strogatz_graph():\n",
        "    pass\n",
        "\n",
        "def test_find_simulated_fb_p():\n",
        "    G = create_fb_graph()\n",
        "    \n",
        "    true_ws_graph = nx.watts_strogatz_graph(G.number_of_nodes(), G.number_of_edges(), G.)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
